{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:6da8e26c01aad648f0d87adffb5544959d5b65854a35c152d54bec2ceec225dd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Linear regression\n",
      "\n",
      "We reproduce Figure 7.7 of Murphy's book and follow his code `pmtk3/matlabTools/stats/polyDataMake.m`.  For `lambda=0.0` we have ordinary least squares.  For `lambda>0` we have ridge regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Gadfly, Interact"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "slide_helper": "subslide_end",
       "slide_type": "subslide"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Create toy data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# following pmtk3/matlabTools/stats/polyDataMake.m\n",
      "n = 5                            # number of data points\n",
      "#xtrain = linspace(0, 20, n)       # training locations\n",
      "xtrain = rand(n)*20\n",
      "xtest  = (0:0.1:20)               # test locations\n",
      "scalex(x) = (x-10)/10             # scale x between -1 and 1\n",
      "sigma2 = 4                        # noise variance\n",
      "w = [-1.5; 1/9]                   # true weights\n",
      "fun(x) = w[1]*x + w[2]*x.^2       # true function\n",
      "ytrain = fun(xtrain) + randn(size(xtrain,1))*sqrt(sigma2)\n",
      "ytest  = fun(xtest ) + randn(size(xtest ,1))*sqrt(sigma2)\n",
      "ytrain = ytrain - mean(ytrain)\n",
      "ytest  = ytest  - mean(ytest )\n",
      "phi(x, d) = x.^((0:d)')            # basis function"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_number": 3,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 3,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Create plots for underfitting, just right and overfitting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = hstack([begin\n",
      "    Xtrain = phi(scalex(xtrain), d)    # training features\n",
      "    Xtest  = phi(scalex(xtest), d);    # test features\n",
      "    wpred = (Xtrain' * Xtrain) \\ Xtrain' * ytrain;\n",
      "    ytestpred = Xtest*wpred;\n",
      "    plot(layer(x=xtrain, y=ytrain   , Geom.point), \n",
      "         layer(x=xtest , y=ytestpred, Geom.line),\n",
      "         Guide.title(\"d = $(d): $({1=>\"underfitting\", 2=>\"just right\", 10=>\"overfitting\"}[d])\"))\n",
      "    end for d in [1, 2, 10]]...)\n",
      "draw(PDF(\"overfitting.pdf\", 9inch, 3inch), p)\n",
      "set_default_plot_size(20cm, 10cm)\n",
      "display(p)"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 5,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 5,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Maximum likelihood estimation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@manipulate for d in [0:20]\n",
      "    Xtrain = phi(scalex(xtrain), d)    # training features\n",
      "    Xtest  = phi(scalex(xtest), d);    # test features\n",
      "    wpred  = (Xtrain' * Xtrain) \\ Xtrain' * ytrain;\n",
      "    ytestpred = Xtest*wpred;\n",
      "    set_default_plot_size(20cm, 10cm)\n",
      "    p1 = plot(layer(x=xtrain, y=ytrain   , Geom.point), \n",
      "              layer(x=xtest , y=ytestpred, Geom.line))\n",
      "    p2 = plot(      x=0:d   , y=wpred,     Guide.xlabel(\"\"), Guide.ylabel(\"w\"))\n",
      "    hstack(p1, p2)\n",
      "end"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 7,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 7,
       "slide_type": "subslide"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Ridge regression and Bayesian linear regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@manipulate for d in [0:20], lambda in [0, 10.0 .^(-12:2)], Bayesian in [0, 1]\n",
      "    Xtrain = phi(scalex(xtrain), d)    # training features\n",
      "    Xtest  = phi(scalex(xtest), d);    # test features\n",
      "    Vn     = (lambda*eye(d+1) + Xtrain' * Xtrain)\n",
      "    wpred  = Vn \\ Xtrain' * ytrain;\n",
      "    ytestpred = Xtest*wpred;\n",
      "    stds = sqrt(sigma2+sigma2*sum((Xtest/Vn).*Xtest,2))\n",
      "    set_default_plot_size(20cm, 10cm)\n",
      "    p = []\n",
      "    if Bayesian==0\n",
      "        plot(layer(x=xtrain, y=ytrain   , Geom.point), \n",
      "             layer(x=xtest , y=ytestpred, Geom.line))\n",
      "    else\n",
      "        plot(layer(x=xtrain, y=ytrain   , Geom.point), \n",
      "        layer(x=xtest , y=ytestpred, ymin=ytestpred-stds, ymax=ytestpred+stds, Geom.line, Geom.ribbon))\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {
      "internals": {
       "frag_helper": "fragment_end",
       "frag_number": 9,
       "slide_helper": "subslide_end"
      },
      "slide_helper": "slide_end",
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}